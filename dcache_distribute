#!/usr/bin/env python
# Tool to distribute all datasets on dCache - uses simple greedy algorithm
# by Fred Stober (stober@cern.ch)

import sys, os, copy, json, optparse
from utils import get_cached, expath, progress, get_pool_infos, fn2ddn, filterMoveable, writeTransferCommands, get_chimera_data, dCacheInfo

parser = optparse.OptionParser()
parser.add_option("-h", "--host", dest="host", default='http://192.108.45.36:2288', help="select by dcache host")
parser.add_option("-c", "--chimera", dest="chimera", default=expath('~/storage_scratch/chimera-dump/current'), help="select by chimera source file")
opts, args = parser.parse_args()

# Write transfer file
def writeTransferFile(fn, transfer_list):
	json.dump(transfer_list, open(fn, 'w'))
	print 'Written result to', fn

def getPoolOverview():
	result_flat = {}
	result_total = 0
	for pool in get_pool_infos(opts.host):
		if 'space' not in pool:
			print 'Pool %s skipped - no space information available!', pool['name']
			continue
#		if not poolFilter(pool):
#			continue
		if not pool['name'].endswith('D_cms'):
			continue
		pool['free'] = pool['space']['free'] + pool['space']['removable']
		result_flat[pool['name']] = pool
		result_total += pool['space']['total']
	return (result_flat, result_total)


# Return dictionary ds -> {'files': ds files, 'size': ds size, <pool>: size on pool, ...}
def getDataPackagesBefore():
	result = {}
	iter_chimera = get_chimera_data(opts.chimera)
	for entry in filterMoveable(progress(iter_chimera)):
		ds = fn2ddn(entry[dCacheInfo.pfn])
		ds_dict = result.setdefault(ds, {})
		ds_dict['files'] = ds_dict.get('files', 0) + 1
		entry_locations = entry.get(dCacheInfo.location, [])
		ds_dict['size'] = ds_dict.get('size', 0) + entry[dCacheInfo.size] * len(entry_locations)
		for loc in entry_locations:
			ds_dict[loc] = ds_dict.get(loc, 0) + entry[dCacheInfo.size]
	return result


# Return dictionary ds -> {<pool>: size delta to reach optimum, ...}
def getPoolTargetSize(packages, pools):
	result = {}
	for ds in sorted(packages, key = lambda k: packages[k]['size']):
		if '/disk-only/' not in ds:
			continue
		ignore = False
		# IGNORED, 'unmerged']:#, 'disk-only/dev', '/user', '/temp/']:
		for k in ['PhEDEx_Debug', 'LoadTest']:
			if k in ds:
				ignore = True
		if ignore:
			continue
		if ds.endswith('store'):
			continue
		if packages[ds]['size'] == 0:
			continue
		imbalance = {}#'avg': packages[ds]['size'] / packages[ds]['files']}
		for pool in sorted(pools):
			# positive => migrate towards, negative => migrate away
			pool_frac = pools[pool]['space']['total'] / pools_total
			ds_usage_optimum = packages[ds]['size'] * pool_frac
			imbalance[pool] = ds_usage_optimum - packages[ds].get(pool, 0)
		result[ds] = imbalance

	return result


# Return list of move operations to reach optimum within a dataset
def getTransfers(ds_imbalance):
	result = []
	result_packages = {}
	iter_chimera = get_chimera_data(opts.chimera)
	for entry in filterMoveable(progress(iter_chimera)):
		ds = fn2ddn(entry[dCacheInfo.pfn])
		if ds not in ds_imbalance:
			continue
		size = entry[dCacheInfo.size]
		ds_poolimbalance = ds_imbalance[ds]
		package_info = result_packages.setdefault(ds, {})
		package_info['files'] = package_info.get('files', 0) + 1
		moveFile = True
		targets = []
		for source_pool in entry[dCacheInfo.location]:
			source_goal = ds_poolimbalance.get(source_pool)
			if source_goal and moveFile:
				if source_goal < 0:
					target_pool = sorted(ds_poolimbalance, key = lambda k: -ds_poolimbalance[k])[0]
					if (target_pool not in entry[dCacheInfo.location]) and (target_pool not in targets):
						target_goal = ds_poolimbalance[target_pool]
						if (source_goal + size < 0):# and (target_goal - size > 0):
							ds_poolimbalance[source_pool] = ds_poolimbalance[source_pool] + size
							ds_poolimbalance[target_pool] = ds_poolimbalance[target_pool] - size
							result.append((entry[dCacheInfo.dcache_id], size, source_pool, target_pool))
							package_info[target_pool] = package_info.get(target_pool, 0) + size
							package_info['size'] = package_info.get('size', 0) + size
							targets.append(target_pool)
#							moveFile = False # Move only one file replica
							continue
			package_info[source_pool] = package_info.get(source_pool, 0) + size
			package_info['size'] = package_info.get('size', 0) + size
	return (result, ds_imbalance, result_packages)


# Returns dictionaries with transfer volumes by pool
def getTransferVolumeByPool(transfer_list):
	pool_in = {}
	pool_out = {}
	pool_delta = {}
	for (dcache_id, size, source, target) in transfer_list:
		pool_in[target] = pool_in.get(target, 0) + size
		pool_delta[target] = pool_delta.get(target, 0) + size
		pool_out[source] = pool_out.get(source, 0) - size
		pool_delta[source] = pool_delta.get(source, 0) - size
	return (pool_in, pool_out, pool_delta)


# Return dictionary with pool imbalances - after the inter-ds transfers are done
def getPoolImbalance(pools, pools_total, pool_delta, packages):
	allds_size = 0
	for ds in packages:
		allds_size += sum(map(lambda pool: packages[ds].get(pool, 0), pools))

	result = {}
	for pool in pools:
		pool_usage_optimal = allds_size / pools_total * pools[pool]['space']['total']
		pool_usage_new = sum(map(lambda ds: packages[ds].get(pool, 0), packages))
		pool_delta.get(pool, 0) + pools[pool]['space']['used']
		result[pool] = pool_usage_optimal - pool_usage_new # negative - move away; positive - migrate towards
	return result


# Return dictionary of migrations on dataset level to balance global pools imbalances
def getDSPoolTransfers(packages, pool_imbalance):
	pool_source_list = filter(lambda p: pool_imbalance[p] < 0, pool_imbalance)
	pool_target_list = filter(lambda p: pool_imbalance[p] > 0, pool_imbalance)
	result = {}
	for ds in packages:
		for pool_source in filter(lambda p: p in packages[ds], pool_source_list):
			ds_size = packages[ds].get(pool_source, 0)
			if pool_imbalance[pool_source] + ds_size < 0:
				for pool_target in filter(lambda p: p not in packages[ds], pool_target_list):
					if (pool_target not in packages[ds]) and (pool_imbalance[pool_target] - ds_size > 0):
						pool_imbalance[pool_source] = pool_imbalance[pool_source] + ds_size
						pool_imbalance[pool_target] = pool_imbalance[pool_target] - ds_size
						packages[ds][pool_target] = packages[ds].pop(pool_source)
						result.setdefault(ds, []).append((pool_source, pool_target))
						break
	return result


# Return list of move operations to reach optimum within a pool
def getFileTransfersFromPoolsTransfers(pool_transfers, pool_imbalance):
	result = []
	result_packages = {}
	iter_chimera = get_chimera_data(opts.chimera)
	for entry in filterMoveable(progress(iter_chimera)):
		ds = fn2ddn(entry[dCacheInfo.pfn])
		if ds not in pool_transfers:
			continue
		size = entry[dCacheInfo.size]
		package_info = result_packages.setdefault(ds, {})
		package_info['files'] = package_info.get('files', 0) + 1
		for (source_pool, target_pool) in pool_transfers[ds]:
			if source_pool in entry.get(dCacheInfo.location, []):
				source_goal = pool_imbalance.get(source_pool)
				pool_imbalance[source_pool] = pool_imbalance[source_pool] + size
				pool_imbalance[target_pool] = pool_imbalance[target_pool] - size
				result.append((entry[dCacheInfo.dcache_id], size, source_pool, target_pool))
			package_info[target_pool] = package_info.get(target_pool, 0) + size
			package_info['size'] = package_info.get('size', 0) + size
	return (result, pool_imbalance, result_packages)


##########################################################################

print 'Getting pool overview...'
(pools, pools_total) = getPoolOverview()
print len(pools), 'disk-only pools found'
print 'Getting file packages (~datasets)...'
packages = getDataPackagesBefore()
print len(packages), 'packages found', sum(map(lambda ds: packages[ds]['files'], packages)), 'files'
print 'Calculating dataset and pool imbalance...'
ds_imbalance = getPoolTargetSize(packages, pools)
num_balanced_files = sum(map(lambda ds: packages[ds]['files'], ds_imbalance))
print len(ds_imbalance), 'packages optimized', num_balanced_files, 'files'
print 'Calculating transfers...'
(transfer_list, ds_imbalance_new, packages_new) = getTransfers(copy.deepcopy(ds_imbalance))
print len(transfer_list), 'transfers needed', '%.1f' % (float(len(transfer_list)) / num_balanced_files * 100.), '%'
print 'Calculating transfer volumes...'
(pool_in, pool_out, pool_delta) = getTransferVolumeByPool(transfer_list)
print 'Calculating global pool imbalances...'
pool_imbalance = getPoolImbalance(pools, pools_total, pool_delta, packages_new)
pool_ds_transfers = getDSPoolTransfers(packages_new, copy.deepcopy(pool_imbalance))
print len(pool_ds_transfers), 'global pool migrations of datasets'
print 'Calculating global pool transfers...'
(transfer_list_g, pool_imbalance_new, packages_new_g) = getFileTransfersFromPoolsTransfers(pool_ds_transfers, copy.deepcopy(pool_imbalance))
print len(transfer_list_g), 'transfers needed', '%.1f' % (float(len(transfer_list_g)) / num_balanced_files * 100.), '%'

##########################################################################

print '=' * 50
print 'Results:'

writeTransferFile(expath('~/software/tmp/dcache_distribute_transfers_global.json'), transfer_list_g)
writeTransferFile(expath('~/software/tmp/dcache_distribute_transfers.json'), transfer_list)

def printImbalance(ds_imbalance, packages):
	for ds in sorted(ds_imbalance):
		print ds
		for pool in sorted(ds_imbalance[ds], key = lambda x: ds_imbalance[ds][x]):
			print '\t', pool, ds_imbalance[ds][pool] / (packages[ds]['size'] / packages[ds]['files'])
		return

#printImbalance(ds_imbalance, packages)
#printImbalance(ds_imbalance_new, packages_new)

def writeDSImbalanceMetric():
	import math
	fp = open(expath('~/software/tmp/dcache_distribute_imbalance_metric'), 'w')
	for ds in ds_imbalance:
		metric_old = math.sqrt(sum(map(lambda p: (ds_imbalance[ds][p] / packages[ds]['size'])**2, ds_imbalance[ds])))
		metric_new = math.sqrt(sum(map(lambda p: (ds_imbalance_new[ds][p] / packages[ds]['size'])**2, ds_imbalance[ds])))
		fp.write(ds + ' ' + str(metric_old) + ' ' + str(metric_new) + ' ')
		fp.write(str(packages[ds]['size']) + ' ' + str(packages[ds]['files']) + '\n')
		total_imb_old = int(sum(map(lambda p: ds_imbalance[ds].get(p, 0), ds_imbalance[ds])))
		total_imb_new = int(sum(map(lambda p: ds_imbalance_new[ds].get(p, 0), ds_imbalance[ds])))
		if total_imb_old or total_imb_new:
			print 'Total imbalance is inconsistent'
			print ds, packages[ds]['size'], packages[ds]['files'], total_imb_new, total_imb_old
	fp.close()
	print 'Written result to', fp.name

writeDSImbalanceMetric()

def printPoolChanges(pools, pool_delta, pool_in, pool_out, packages, packages_new):
	print
	print
	print 'Pool changes'
	print '-' * 40
	print 'I: in, O: out, D: delta, T: total space, F: free space'
	print 'Pool info | B: used, b: used rel., A: predicted used, a: predicted used rel.'
	print '  Dataset | U: used, u: used rel., P: predicted used, p: predicted used rel.'
	for pool in sorted(pool_delta):
		pool_free = (pools[pool]['space']['free'] + pools[pool]['space']['removable'])

		print pool,
		print 'I%7.3f' % (pool_in[pool] / 1.e12),#
		print 'O%7.3f' % (pool_out[pool] / 1.e12),
#		print 'D%7.3f' % (pool_delta[pool] / 1.e12),
		print 'T%7.3f' % (pools[pool]['space']['total'] / 1.e12),
#		print 'F%7.3f' % (pools[pool]['space']['free'] / 1.e12),
		print '|',
		print 'B%7.3f' % (pools[pool]['space']['used'] / 1.e12),
		print 'b%.3f' % (pools[pool]['space']['used'] / pools[pool]['space']['total']),
#		print 'A%.3f' % (float(pool_delta[pool] + pools[pool]['space']['used']) / 1.e12),
#		print 'a%.3f' % (float(pool_delta[pool] + pools[pool]['space']['used']) / pools[pool]['space']['total']),
		print '|',
		print 'U%7.3f' % (sum(map(lambda ds: packages.get(ds, {}).get(pool, 0), packages_new)) / 1.e12),
		print 'u%.3f' % (sum(map(lambda ds: packages.get(ds, {}).get(pool, 0), packages_new)) / pools[pool]['space']['total']),
		print 'P%7.3f' % (sum(map(lambda ds: packages_new.get(ds, {}).get(pool, 0), packages_new)) / 1.e12),
		print 'p%.3f' % (sum(map(lambda ds: packages_new.get(ds, {}).get(pool, 0), packages_new)) / pools[pool]['space']['total'] ),
		print

	print '              Total:',
	print 'I%7.3f' % (sum(map(lambda pool: pool_in[pool] / 1.e12, pool_delta))),
	print 'O%7.3f' % (sum(map(lambda pool: pool_out[pool] / 1.e12, pool_delta)))

printPoolChanges(pools, pool_delta, pool_in, pool_out, packages, packages_new)

def printGlobalImprovement(pool_imbalance, pool_imbalance_new):
	print
	print
	print 'Improvement (delta_opt) due to global balancing'
	print '(imbalances before and after balancing operation)'
	print '-' * 40
	for x in sorted(pool_imbalance, key = lambda x: pool_imbalance[x]):
		print x, '%+.3f' % (pool_imbalance[x] / 1.e12), '%+.3f' % (pool_imbalance_new[x] / 1.e12)
	print

printGlobalImprovement(pool_imbalance, pool_imbalance_new)

def printPoolDSDistribution(pools, pools_total, packages):
	print
	print
	print 'Dataset distribution over pools'
	print '-' * 40
	poolDSNumber = {}
	poolDSNumberGTP = {}
	poolDSNumberLTP = {}
	poolDSSize = {}
	poolDSSizeGTP = {}
	poolDSSizeLTP = {}
	for ds in packages:
		for pool in pools:
			if packages[ds].get(pool, 0):
				poolDSNumber[pool] = poolDSNumber.get(pool, 0) + 1
				poolDSSize[pool] = poolDSSize.get(pool, 0) + packages[ds].get(pool, 0)
				if packages[ds]['files'] >= len(pools):
					poolDSNumberGTP[pool] = poolDSNumberGTP.get(pool, 0) + 1
					poolDSSizeGTP[pool] = poolDSSizeGTP.get(pool, 0) + packages[ds].get(pool, 0)
				else:
					poolDSNumberLTP[pool] = poolDSNumberLTP.get(pool, 0) + 1
					poolDSSizeLTP[pool] = poolDSSizeLTP.get(pool, 0) + packages[ds].get(pool, 0)
	maxGTP = float(max(poolDSNumberGTP.values()))
	for pool in sorted(poolDSNumber):
		poolSize = float(pools[pool]['space']['total'])
		poolFrac = poolSize / pools_total
		print pool,

		print 'total',
		print '%5d  ' % poolDSNumber.get(pool, 0),
		print '%5.1f%%' % (poolDSNumber.get(pool, 0) / float(len(packages)) * 100.),

		print '(#f>=#p)',
		print '%5d  ' % poolDSNumberGTP.get(pool, 0),
		print '%5.1f%%' % (poolDSNumberGTP.get(pool, 0) / maxGTP * 100.),

		print '(#f< #p)',
		print '%5d  ' % poolDSNumberLTP.get(pool, 0),
		dsFrac = poolDSNumberLTP.get(pool, 0) / float(sum(poolDSNumberLTP.values()))
#		print '%5.1f%%' % (dsFrac * 100.),
		print '%5.1f%%' % (dsFrac / poolFrac * 100.),
		print
		print ' ' * len(pool),

		print '     ',
		print '%5.1fTB' % (poolDSSize.get(pool, 0) / 1.e12),
		print '%5.1f%%' % (poolDSSize.get(pool, 0) / poolSize * 100.),

		print '        ',
		print '%5.1fTB' % (poolDSSizeGTP.get(pool, 0) / 1.e12),
		allDSSizeGTP = float(sum(poolDSSizeGTP.values()))
		print '%5.1f%%' % (poolDSSizeGTP.get(pool, 0) / allDSSizeGTP / poolFrac * 100.),

		print '        ',
		print '%5.1fTB' % (poolDSSizeLTP.get(pool, 0) / 1.e12),
#		print '%5.1f%%' % (poolDSSizeLTP.get(pool, 0) / poolSize * 100.),
		print '%5.1f%%' % ((poolDSSizeLTP.get(pool, 0) / poolSize) / poolFrac * 100.),
		print

printPoolDSDistribution(pools, pools_total, packages_new)
