#!/usr/bin/env python
# Tool to distribute all datasets on dCache - uses simple greedy algorithm
# by Fred Stober (stober@cern.ch)

import sys, os, copy
from toolKIT.utils import expath, progress, get_cached
from toolKIT.chimera import dCacheInfo, get_chimera_data
from toolKIT.dCache import get_pool_infos
from toolKIT.dCache_distribute import filterMoveable, writeTransferCommands, writeTransferFile
from toolKIT.lfntools import fn2ddn
from toolKIT.monitoring import happyface_upload

dCacheWebHost = 'http://192.108.45.36:2288'

# Play back old storage 
#from toolKIT.chimera import cache_chimera_data
#cache_chimera_data(expath('~/storage_scratch/chimera-dump'),
#	expath('~/storage_scratch/storage-information'), 201407160705)
chimera_path = expath('~/storage_scratch/chimera-dump/current')

def getPoolOverview():
	result_flat = {}
	result_total = 0
	for pool in get_pool_infos(dCacheWebHost):
		if 'space' not in pool:
			print 'Pool %s skipped - no space information available!', pool['name']
			continue
#		if not poolFilter(pool):
#			continue
		if not pool['name'].endswith('D_cms'):
			continue
		pool['free'] = pool['space']['free'] + pool['space']['removable']
		result_flat[pool['name']] = pool
		result_total += pool['space']['total']
	return (result_flat, result_total)

# Return dictionary ds -> {'files': ds files, 'size': ds size, <pool>: size on pool, ...}
def getDataPackagesBefore():
	result = {}
	iter_chimera = get_chimera_data(chimera_path)
	for entry in filterMoveable(progress(iter_chimera)):
		ds = fn2ddn(entry[dCacheInfo.pfn])
		ds_dict = result.setdefault(ds, {})
		ds_dict['files'] = ds_dict.get('files', 0) + 1
		entry_locations = entry.get(dCacheInfo.location, [])
		ds_dict['size'] = ds_dict.get('size', 0) + entry[dCacheInfo.size] * len(entry_locations)
		for loc in entry_locations:
			ds_dict[loc] = ds_dict.get(loc, 0) + entry[dCacheInfo.size]
	return result

# Return dictionary ds -> {<pool>: size delta to reach optimum, ...}
def getPoolTargetSize(packages, pools):
	result = {}
	for ds in sorted(packages, key = lambda k: packages[k]['size']):
		if '/disk-only/' not in ds:
			continue
		ignore = False
		# IGNORED, 'unmerged']:#, 'disk-only/dev', '/user', '/temp/']:
		for k in ['PhEDEx_Debug', 'LoadTest']:
			if k in ds:
				ignore = True
		if ignore:
			continue
		if ds.endswith('store'):
			continue
		if packages[ds]['size'] == 0:
			continue
		imbalance = {}#'avg': packages[ds]['size'] / packages[ds]['files']}
		for pool in sorted(pools):
			# positive => migrate towards, negative => migrate away
			pool_frac = pools[pool]['space']['total'] / pools_total
			ds_usage_optimum = packages[ds]['size'] * pool_frac
			imbalance[pool] = ds_usage_optimum - packages[ds].get(pool, 0)
		result[ds] = imbalance

	return result


# Return list of move operations to reach optimum within a dataset
def getTransfers(ds_imbalance):
	result = []
	result_packages = {}
	iter_chimera = get_chimera_data(chimera_path)
	for entry in filterMoveable(progress(iter_chimera)):
		ds = fn2ddn(entry[dCacheInfo.pfn])
		if ds not in ds_imbalance:
			continue
		size = entry[dCacheInfo.size]
		ds_poolimbalance = ds_imbalance[ds]
		package_info = result_packages.setdefault(ds, {})
		package_info['files'] = package_info.get('files', 0) + 1
		moveFile = True
		targets = []
		for source_pool in entry[dCacheInfo.location]:
			source_goal = ds_poolimbalance.get(source_pool)
			if source_goal and moveFile:
				if source_goal < 0:
					target_pool = sorted(ds_poolimbalance, key = lambda k: -ds_poolimbalance[k])[0]
					if (target_pool not in entry[dCacheInfo.location]) and (target_pool not in targets):
						target_goal = ds_poolimbalance[target_pool]
						if (source_goal + size < 0):# and (target_goal - size > 0):
							ds_poolimbalance[source_pool] = ds_poolimbalance[source_pool] + size
							ds_poolimbalance[target_pool] = ds_poolimbalance[target_pool] - size
							result.append((entry[dCacheInfo.dcache_id], size, source_pool, target_pool))
							package_info[target_pool] = package_info.get(target_pool, 0) + size
							package_info['size'] = package_info.get('size', 0) + size
							targets.append(target_pool)
#							moveFile = False # Move only one file replica
							continue
			package_info[source_pool] = package_info.get(source_pool, 0) + size
			package_info['size'] = package_info.get('size', 0) + size
	return (result, ds_imbalance, result_packages)

# Returns dictionaries with transfer volumes by pool
def getTransferVolumeByPool(transfer_list):
	pool_in = {}
	pool_out = {}
	pool_delta = {}
	for (dcache_id, size, source, target) in transfer_list:
		pool_in[target] = pool_in.get(target, 0) + size
		pool_delta[target] = pool_delta.get(target, 0) + size
		pool_out[source] = pool_out.get(source, 0) - size
		pool_delta[source] = pool_delta.get(source, 0) - size
	return (pool_in, pool_out, pool_delta)

# Return dictionary with pool imbalances - after the inter-ds transfers are done
def getPoolImbalance(pools, pools_total, pool_delta, packages):
	allds_size = 0
	for ds in packages:
		allds_size += sum(map(lambda pool: packages[ds].get(pool, 0), pools))

	result = {}
	for pool in pools:
		pool_usage_optimal = allds_size / pools_total * pools[pool]['space']['total']
		pool_usage_new = sum(map(lambda ds: packages[ds].get(pool, 0), packages))
		pool_delta.get(pool, 0) + pools[pool]['space']['used']
		result[pool] = pool_usage_optimal - pool_usage_new # negative - move away; positive - migrate towards
	return result

# Return dictionary of migrations on dataset level to balance global pools imbalances
def getDSPoolTransfers(packages, pool_imbalance):
	pool_source_list = filter(lambda p: pool_imbalance[p] < 0, pool_imbalance)
	pool_target_list = filter(lambda p: pool_imbalance[p] > 0, pool_imbalance)
	result = {}
	for ds in packages:
		for pool_source in filter(lambda p: p in packages[ds], pool_source_list):
			ds_size = packages[ds].get(pool_source, 0)
			if pool_imbalance[pool_source] + ds_size < 0:
				for pool_target in filter(lambda p: p not in packages[ds], pool_target_list):
					if (pool_target not in packages[ds]) and (pool_imbalance[pool_target] - ds_size > 0):
						pool_imbalance[pool_source] = pool_imbalance[pool_source] + ds_size
						pool_imbalance[pool_target] = pool_imbalance[pool_target] - ds_size
						packages[ds][pool_target] = packages[ds].pop(pool_source)
						result.setdefault(ds, []).append((pool_source, pool_target))
						break
	return result

# Return list of move operations to reach optimum within a pool
def getFileTransfersFromPoolsTransfers(pool_transfers, pool_imbalance):
	result = []
	result_packages = {}
	iter_chimera = get_chimera_data(chimera_path)
	for entry in filterMoveable(progress(iter_chimera)):
		ds = fn2ddn(entry[dCacheInfo.pfn])
		if ds not in pool_transfers:
			continue
		size = entry[dCacheInfo.size]
		package_info = result_packages.setdefault(ds, {})
		package_info['files'] = package_info.get('files', 0) + 1
		for (source_pool, target_pool) in pool_transfers[ds]:
			if source_pool in entry.get(dCacheInfo.location, []):
				source_goal = pool_imbalance.get(source_pool)
				pool_imbalance[source_pool] = pool_imbalance[source_pool] + size
				pool_imbalance[target_pool] = pool_imbalance[target_pool] - size
				result.append((entry[dCacheInfo.dcache_id], size, source_pool, target_pool))
			package_info[target_pool] = package_info.get(target_pool, 0) + size
			package_info['size'] = package_info.get('size', 0) + size
	return (result, pool_imbalance, result_packages)

